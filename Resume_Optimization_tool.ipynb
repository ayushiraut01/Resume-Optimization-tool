{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt1I8gg7gW8elp8nSgjg+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushiraut01/Resume-Optimization-tool/blob/main/Resume_Optimization_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jAWxWKyHavJ",
        "outputId": "50d0b7f8-7c52-4576-ca4d-9a652286e879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas spacy sklearn docx2txt pdfminer.six\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC-t2boHH-mC",
        "outputId": "1c2a376a-213f-43b1-8d9d-4d13450282e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=59504bb8086d38f454f104263b9a58a42154ceeeeefbfa64fc2e1a6b0794903d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfq6kkbmIKWm",
        "outputId": "0bcc482b-8d86-4b7e-c07e-9cc1fec2b84e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/5.6 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfminer\n",
        "import docx2txt\n",
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_resume_text(file_path):\n",
        "    \"\"\"Extract text from a resume file (PDF or DOCX).\"\"\"\n",
        "    if file_path.endswith('.pdf'):\n",
        "        text = extract_text(file_path)\n",
        "    elif file_path.endswith('.docx'):\n",
        "        text = docx2txt.process(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "Ra5Y8ZrpHse2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def analyze_resume(text):\n",
        "    \"\"\"Extract relevant details like skills, experience, and education from resume.\"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    skills = [\"Python\", \"Java\", \"Machine Learning\", \"Data Science\", \"SQL\", \"Django\", \"Flask\",\"MYSQL\",\"AWS\",\"laravel\"]  # Add more relevant skills\n",
        "    extracted_skills = [token.text for token in doc if token.text in skills]\n",
        "\n",
        "    years_experience = sum(1 for token in doc if token.text.isdigit() and int(token.text) <= 50)  # Approximate experience count\n",
        "\n",
        "    return {\n",
        "        \"skills\": extracted_skills,\n",
        "        \"experience\": years_experience\n",
        "    }\n"
      ],
      "metadata": {
        "id": "lvoHyP-zITWt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "source": [
        "!pip install textstat # Install the 'textstat' library"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2B0fjv2YThC",
        "outputId": "bd4c38e8-196d-48e8-b21e-6500e2929a4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\n",
            "Successfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textstat import flesch_reading_ease\n",
        "\n",
        "def score_resume(resume_text, extracted_info):\n",
        "    \"\"\"Assign a score to the resume based on various factors.\"\"\"\n",
        "    base_score = 50\n",
        "\n",
        "    # Skills Score\n",
        "    skill_count = len(extracted_info[\"skills\"])\n",
        "    skill_score = min(skill_count * 5, 20)  # Max 20 points\n",
        "\n",
        "    # Experience Score\n",
        "    experience_score = min(extracted_info[\"experience\"] * 3, 20)  # Max 20 points\n",
        "\n",
        "    # Readability Score\n",
        "    readability = flesch_reading_ease(resume_text)\n",
        "    readability_score = max(0, min((readability / 10), 10))  # Normalize between 0-10\n",
        "\n",
        "    total_score = base_score + skill_score + experience_score + readability_score\n",
        "    return round(total_score, 2)\n"
      ],
      "metadata": {
        "id": "z9aMHVm3IV_O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "source": [
        "!pip install textstat # Install the 'textstat' library"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7-g-imhIcbi",
        "outputId": "473dced8-c638-47a9-9522-b42ad6118fff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.5)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.0.32)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_resume(file_path):\n",
        "    \"\"\"Full resume evaluation pipeline.\"\"\"\n",
        "    resume_text = extract_resume_text(file_path)\n",
        "    extracted_info = analyze_resume(resume_text)\n",
        "    score = score_resume(resume_text, extracted_info)\n",
        "\n",
        "    print(\"\\nResume Analysis Results:\")\n",
        "    print(f\"Extracted Skills: {extracted_info['skills']}\")\n",
        "    print(f\"Years of Experience: {extracted_info['experience']}\")\n",
        "    print(f\"Resume Score: {score}/100\")\n"
      ],
      "metadata": {
        "id": "dqOPcdhPIkQG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install language_tool_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRt0LfbPXvQ",
        "outputId": "e5ce68fe-feb4-4507-8aa2-1bb050e2c329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.8.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (4.67.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2025.1.31)\n",
            "Downloading language_tool_python-2.8.2-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: language_tool_python\n",
            "Successfully installed language_tool_python-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import docx2txt\n",
        "import pdfminer\n",
        "import spacy\n",
        "import re\n",
        "import language_tool_python # This line was missing\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "from textstat import flesch_reading_ease\n",
        "from collections import Counter\n",
        "\n",
        "# Load NLP Model & Grammar Checker\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "tool = language_tool_python.LanguageToolPublicAPI('en-US')  # Grammar checking\n",
        "\n",
        "# Predefined Skills List (Expand this as needed)\n",
        "SKILLS_DB = {\"Python\", \"Java\", \"Machine Learning\", \"Data Science\", \"SQL\", \"Django\", \"Flask\",\n",
        "             \"NLP\", \"TensorFlow\", \"Keras\", \"Deep Learning\", \"AWS\", \"React\", \"JavaScript\",\n",
        "             \"C++\", \"C#\", \"HTML\", \"CSS\", \"Angular\", \"Docker\", \"Kubernetes\", \"Git\"}\n",
        "\n",
        "# Skill pattern for better extraction\n",
        "SKILL_PATTERN = re.compile(r'\\b(' + '|'.join(SKILLS_DB) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "# ---------------- Step 1: Extract Resume Text ---------------- #\n",
        "def extract_resume_text(file_path):\n",
        "    \"\"\"Extract text from a resume file (PDF or DOCX).\"\"\"\n",
        "    if file_path.endswith('.pdf'):\n",
        "        text = extract_text(file_path)\n",
        "    elif file_path.endswith('.docx'):\n",
        "        text = docx2txt.process(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
        "    return text.strip()\n",
        "\n",
        "# ---------------- Step 2: Extract Key Information ---------------- #\n",
        "def analyze_resume(text):\n",
        "    \"\"\"Extract skills, experience, and relevant keywords from the resume.\"\"\"\n",
        "    doc = nlp(text.lower())  # Convert text to lowercase for uniform processing\n",
        "\n",
        "    # Extract Skills using Pattern Matching and NLP\n",
        "    extracted_skills = set(SKILL_PATTERN.findall(text))  # Pattern-based extraction\n",
        "    extracted_skills.update({token.text for token in doc if token.text in SKILLS_DB})  # NLP-based extraction\n",
        "\n",
        "    # Approximate Experience Extraction\n",
        "    experience_years = re.findall(r'(\\d+)\\s*years?', text)\n",
        "    years_experience = max(map(int, experience_years), default=0)  # Get max years found\n",
        "\n",
        "    # Count Keywords Occurrences\n",
        "    word_freq = Counter([token.text for token in doc if token.is_alpha])\n",
        "\n",
        "    return {\n",
        "        \"skills\": extracted_skills,\n",
        "        \"experience\": years_experience,\n",
        "        \"word_frequencies\": word_freq\n",
        "    }\n",
        "\n",
        "# ---------------- Step 3: Grammar & Formatting Check ---------------- #\n",
        "def grammar_check(text):\n",
        "    \"\"\"Check grammar and spelling issues in the resume.\"\"\"\n",
        "    matches = tool.check(text)\n",
        "    return len(matches), matches[:5]  # Return top 5 grammar issues\n",
        "\n",
        "def check_bullet_formatting(text):\n",
        "    \"\"\"Ensure resume has proper bullet points.\"\"\"\n",
        "    bullet_points = re.findall(r'^\\s*[-•]', text, re.MULTILINE)\n",
        "    return len(bullet_points) > 5  # At least 5 bullet points indicate good formatting\n",
        "\n",
        "# ---------------- Step 4: Job Description Matching ---------------- #\n",
        "def match_job_description(resume_text, job_description):\n",
        "    \"\"\"Compare resume with job description to calculate relevance score.\"\"\"\n",
        "    resume_doc = nlp(resume_text.lower())\n",
        "    job_doc = nlp(job_description.lower())\n",
        "\n",
        "    resume_words = set([token.text for token in resume_doc if token.is_alpha])\n",
        "    job_words = set([token.text for token in job_doc if token.is_alpha])\n",
        "\n",
        "    common_words = resume_words.intersection(job_words)\n",
        "    missing_skills = job_words - resume_words  # Find missing skills\n",
        "\n",
        "    relevance_score = (len(common_words) / len(job_words)) * 100\n",
        "    return round(relevance_score, 2), missing_skills\n",
        "\n",
        "# ---------------- Step 5: Scoring Algorithm ---------------- #\n",
        "def score_resume(resume_text, extracted_info, job_description=\"\"):\n",
        "    \"\"\"Assign a score based on skills, experience, readability, and job relevance.\"\"\"\n",
        "    base_score = 50  # Default base score\n",
        "\n",
        "    # Skills Score\n",
        "    skill_count = len(extracted_info[\"skills\"])\n",
        "    skill_score = min(skill_count * 5, 20)  # Max 20 points\n",
        "\n",
        "    # Experience Score\n",
        "    experience_score = min(extracted_info[\"experience\"] * 3, 20)  # Max 20 points\n",
        "\n",
        "    # Readability Score\n",
        "    readability = flesch_reading_ease(resume_text)\n",
        "    readability_score = max(0, min((readability / 10), 10))  # Normalize to 10 points\n",
        "\n",
        "    # Grammar Check Score\n",
        "    grammar_issues, _ = grammar_check(resume_text)\n",
        "    grammar_score = max(0, 10 - grammar_issues)  # Deduct points for grammar errors\n",
        "\n",
        "    # Bullet Point Score\n",
        "    bullet_score = 5 if check_bullet_formatting(resume_text) else 0  # 5 points for good formatting\n",
        "\n",
        "    # Job Relevance Score\n",
        "    job_match_score = 0\n",
        "    missing_skills = set()\n",
        "    if job_description:\n",
        "        job_match_score, missing_skills = match_job_description(resume_text, job_description)\n",
        "        job_match_score = min(job_match_score, 20)  # Max 20 points\n",
        "\n",
        "    total_score = base_score + skill_score + experience_score + readability_score + job_match_score + grammar_score + bullet_score\n",
        "    return round(total_score, 2), missing_skills\n",
        "\n",
        "# ---------------- Step 6: Full Evaluation ---------------- #\n",
        "def evaluate_resume(file_path, job_description=\"\"):\n",
        "    \"\"\"Complete Resume Evaluation with Job Matching & Feedback.\"\"\"\n",
        "    resume_text = extract_resume_text(file_path)\n",
        "    extracted_info = analyze_resume(resume_text)\n",
        "    score, missing_skills = score_resume(resume_text, extracted_info, job_description)\n",
        "\n",
        "    # Grammar Check\n",
        "    grammar_issues, grammar_suggestions = grammar_check(resume_text)\n",
        "\n",
        "    print(\"\\n📄 **Resume Analysis Results:**\")\n",
        "    print(f\"✅ Extracted Skills: {', '.join(extracted_info['skills'])}\")\n",
        "    print(f\"📆 Years of Experience: {extracted_info['experience']}\")\n",
        "    print(f\"📖 Readability Score: {flesch_reading_ease(resume_text):.2f}\")\n",
        "\n",
        "    if job_description:\n",
        "        print(f\"🎯 Job Relevance Score: {match_job_description(resume_text, job_description)[0]}%\")\n",
        "        if missing_skills:\n",
        "            print(f\"🚀 Missing Skills for Job: {', '.join(missing_skills)}\")\n",
        "\n",
        "    print(f\"🔍 Grammar Issues Found: {grammar_issues}\")\n",
        "    if grammar_issues > 0:\n",
        "        print(\"💡 Top Grammar Suggestions:\")\n",
        "        for issue in grammar_suggestions:\n",
        "            print(f\"  - {issue.message}\")\n",
        "\n",
        "    print(f\"📌 Bullet Point Formatting: {'✅ Properly formatted' if check_bullet_formatting(resume_text) else '⚠ Needs better structuring'}\")\n",
        "    print(f\"⭐ **Final Resume Score: {score}/100**\")\n",
        "\n",
        "# ---------------- Step 7: Run the Program ---------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = input(\"Enter the resume file path: \").strip()\n",
        "    job_description = input(\"Enter the job description (or leave blank): \").strip()\n",
        "    evaluate_resume(file_path, job_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxq_yEBIPRGp",
        "outputId": "fd8b2017-40be-4385-d1c4-6d7c3826614f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the resume file path: /content/Resume_1 AR.pdf\n",
            "Enter the job description (or leave blank): ai intern\n",
            "\n",
            "📄 **Resume Analysis Results:**\n",
            "✅ Extracted Skills: HTML, CSS, TensorFlow, NLP, machine learning, Python, Flask, SQL, Machine Learning\n",
            "📆 Years of Experience: 0\n",
            "📖 Readability Score: -0.10\n",
            "🎯 Job Relevance Score: 100.0%\n",
            "🔍 Grammar Issues Found: 25\n",
            "💡 Top Grammar Suggestions:\n",
            "  - The official name of this software platform is spelled with a capital “H”.\n",
            "  - It seems like there are too many consecutive spaces here.\n",
            "  - It seems like there are too many consecutive spaces here.\n",
            "  - Possible spelling mistake found.\n",
            "  - Possible spelling mistake found.\n",
            "📌 Bullet Point Formatting: ⚠ Needs better structuring\n",
            "⭐ **Final Resume Score: 90/100**\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Add this at the beginning of your notebook or before using language_tool_python:\n",
        "!pip install language_tool_python\n",
        "import language_tool_python"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WulXXB6bbjLE",
        "outputId": "aaef483c-baff-48ea-bf98-569ae8b65463"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.8.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (4.67.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2025.1.31)\n",
            "Downloading language_tool_python-2.8.2-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: language_tool_python\n",
            "Successfully installed language_tool_python-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "sakysr9ycpiz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpI4e1H0fxgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U79BiZiVjomQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}